stargate.environment.config = {
  PROD = {
    aciKafkaUri = "https://kafka-kaffe-prod.pie.apple.com"
    stratosQueueServer = "stratos-queue.corp.apple.com"
    schemaReference = PROD
    hubbleTcpEndpoint = "tcp://hubble-tcp-publish-corp-prod.apple.com:9898"
    hubbleHttpEndpoint = "https://hubble-auth-publish-corp-prod.apple.com"
    cloudConfigApiUri = "https://csccsvc.corp.apple.com"
    dhariUri = "https://dhari.apple.com"
    stargateUri = "https://stargate-platform.apple.com"
    s3EndPoint = "http://store-030.blobstore.apple.com"
    idmsUrl = "https://idmsservice.corp.apple.com/apptoapp/token"
    acsDataPlatformUri = "https://spark.datastudio.apple.com/api/v1"
    pieSecretsUri = "https://secrets.pie.apple.com/v2"
    aciGitHubUri = "github.pie.apple.com"
    sparkPieTelemetryHubbleCluster = Corp
    splunkCluster = iag_prod
    stargateSplunkIndex = stargate
    dataCatalogUri = "https://datacatalog.apple.com/internal/api/ingest"
    appConfigApiUrl = "https://appconfig-svc.corp.apple.com/appconfig/properties"
  }
  UAT = {
    aciKafkaUri = "https://kafka-kaffe-if1.pie.apple.com"
    stratosQueueServer = "stratos-queue-uat.corp.apple.com"
    schemaReference = PROD
    hubbleTcpEndpoint = "tcp://hubble-tcp-publish-corp-uat.apple.com:9898"
    hubbleHttpEndpoint = "https://hubble-auth-publish-corp-uat.apple.com"
    cloudConfigApiUri = "https://csccsvc-uat.corp.apple.com"
    dhariUri = "https://dhari-uat.apple.com"
    stargateUri = "https://stargate-platform-uat.apple.com"
    s3EndPoint = "http://store-030.blobstore.apple.com"
    idmsUrl = "https://idmsservice-uat.corp.apple.com/auth/apptoapp/token"
    acsDataPlatformUri = "https://spark.datastudio.apple.com/api/v1"
    pieSecretsUri = "https://secrets.pie.apple.com/v2"
    aciGitHubUri = "github.pie.apple.com"
    sparkPieTelemetryHubbleCluster = CorpQA
    splunkCluster = iag_prod
    stargateSplunkIndex = stargate_uat
    dataCatalogUri = "https://aml-datahub-uat.g.apple.com/internal/api/ingest"
    appConfigApiUrl = "https://appconfig-svc.corp.apple.com/appconfig/properties"
  }
  QA = {
    aciKafkaUri = "https://kafka-kaffe-if1.pie.apple.com"
    stratosQueueServer = "stratos-queue-uat.corp.apple.com"
    schemaReference = PROD
    hubbleTcpEndpoint = "tcp://hubble-tcp-publish-corp-uat.apple.com:9898"
    hubbleHttpEndpoint = "https://hubble-auth-publish-corp-uat.apple.com"
    cloudConfigApiUri = "https://csccsvc-uat.corp.apple.com"
    dhariUri = "https://dhari-qa.apple.com"
    stargateUri = "https://stargate-platform-qa.apple.com"
    s3EndPoint = "http://store-030.blobstore.apple.com"
    idmsUrl = "https://idmsservice-uat.corp.apple.com/auth/apptoapp/token"
    acsDataPlatformUri = "https://spark.datastudio.apple.com/api/v1"
    pieSecretsUri = "https://secrets.pie.apple.com/v2"
    aciGitHubUri = "github.pie.apple.com"
    sparkPieTelemetryHubbleCluster = CorpQA
    splunkCluster = iag_prod
    stargateSplunkIndex = stargate_qa
    dataCatalogUri = "https://aml-datahub-uat.g.apple.com/internal/api/ingest"
    appConfigApiUrl = "https://appconfig-svc.corp.apple.com/appconfig/properties"
  }
  DEV = {
    aciKafkaUri = "https://kafka-kaffe-if1.pie.apple.com"
    stratosQueueServer = "stratos-queue-uat.corp.apple.com"
    schemaReference = PROD
    hubbleTcpEndpoint = "tcp://hubble-tcp-publish-corp-uat.apple.com:9898"
    hubbleHttpEndpoint = "https://hubble-auth-publish-corp-uat.apple.com"
    cloudConfigApiUri = "https://csccsvc-uat.corp.apple.com"
    dhariUri = "https://dhari-dev.apple.com"
    stargateUri = "https://stargate-platform-dev.apple.com"
    s3EndPoint = "http://store-030.blobstore.apple.com"
    idmsUrl = "https://idmsservice-uat.corp.apple.com/auth/apptoapp/token"
    acsDataPlatformUri = "https://spark.datastudio.apple.com/api/v1"
    pieSecretsUri = "https://secrets.pie.apple.com/v2"
    aciGitHubUri = "github.pie.apple.com"
    sparkPieTelemetryHubbleCluster = CorpQA
    splunkCluster = iag_prod
    stargateSplunkIndex = stargate_dev
    dataCatalogUri = "https://aml-datahub-dev.g.apple.com/internal/api/ingest"
    appConfigApiUrl = "https://appconfig-svc.corp.apple.com/appconfig/properties"
  }
  LOCAL = {
    aciKafkaUri = "https://kafka-kaffe-if1.pie.apple.com"
    stratosQueueServer = "stratos-queue-uat.corp.apple.com"
    schemaReference = PROD
    hubbleTcpEndpoint = "tcp://hubble-tcp-publish-corp-uat.apple.com:9898"
    hubbleHttpEndpoint = "https://hubble-auth-publish-corp-uat.apple.com"
    cloudConfigApiUri = "https://csccsvc-uat.corp.apple.com"
    dhariUri = "https://dhari-dev.apple.com"
    stargateUri = "https://stargate-platform-dev.apple.com"
    s3EndPoint = "http://store-030.blobstore.apple.com"
    idmsUrl = "https://idmsservice-uat.corp.apple.com/auth/apptoapp/token"
    acsDataPlatformUri = "https://spark.datastudio.apple.com/api/v1"
    pieSecretsUri = "https://secrets.pie.apple.com/v2"
    aciGitHubUri = "github.pie.apple.com"
    sparkPieTelemetryHubbleCluster = CorpQA
    splunkCluster = iag_prod
    stargateSplunkIndex = stargate_dev
    dataCatalogUri = "https://aml-datahub-dev.g.apple.com/internal/api/ingest"
    appConfigApiUrl = "https://appconfig-svc.corp.apple.com/appconfig/properties"
  }
}
stargate.knownApps.config = {
  EAI = {
    appName = EAI
    appId = 963
  }
  STRATOS = {
    appName = Stratos
    appId = 4237
  }
  CLOUD_CONFIG = {
    appId = 171358
    appName = CloudConfig
    contextString = cscloudconfig
  }
  DHARI = {
    appId = 172117
    appName = Dhari
    contextString = aml
  }
  STARGATE = {
    appId = 172847
    appName = Stargate
    contextString = aml
  }
  NATIVE_ML_PLATFORM = {
    appId = 177979
    appName = NativeMLPlatform
    contextString = aml
  }
  NATIVE_ML_TEST_SUITE = {
    appId = 181069
    appName = NativeMLTestSuite
    contextString = aml
  }
  DATA_CATALOG = {
    appId = 182080
    appName = DataCatalog
    contextString = Vm4KepzVFf
  }
  GBI_KEYSTONE = {
    appId = 150493
    appName = Orchestrator
    contextString = AAA
    contextVersion = 1
  }
  APP_CONFIG = {
    appId = 136299
    appName = AppConfig
    contextString = nyc
  }
}
stargate.nodeType.config = {
  Switch = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.Switch
    optionsClassName = com.apple.aml.stargate.common.options.SwitchOptions
    aliases = [Gate, Case, CaseStatement, Condition, Conditional, Branch]
  }
  DataGenerator = {
    readerClassName = com.apple.aml.stargate.beam.sdk.triggers.DataGenerator
    optionsClassName = com.apple.aml.stargate.common.options.DataGeneratorOptions
    aliases = [MockData, Data, Sample, SampleData, LoadTest, Sampler, LoadGenerator]
  }
  Sequencer = {
    readerClassName = com.apple.aml.stargate.beam.sdk.triggers.Sequencer
    flinkReaderClassName = com.apple.aml.stargate.flink.source.SequencerSource
    optionsClassName = com.apple.aml.stargate.common.options.SequencerOptions
    aliases = [GenerateSequence, Sequence, Sequencer, Trigger, Ticker, Timer, Frequency, Pulse]
  }
  JavaFunction = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.JavaFunction
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.JavaFunction
    optionsClassName = com.apple.aml.stargate.common.options.JavaFunctionOptions
    aliases = [Function, JavaFunc, Lambda, JavaLambda, Java]
  }
  JavaBiFunction = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.JavaBiFunction
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.JavaBiFunction
    optionsClassName = com.apple.aml.stargate.common.options.JavaFunctionOptions
    aliases = [BiFunction, JavaBiFunc, BiFunc]
  }
  SPELEvaluator = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.SPELEvaluator
    optionsClassName = com.apple.aml.stargate.common.options.SPELOptions
    aliases = [SPEL, Spring, SpringEL, SpringEvaluator]
  }
  FreemarkerEvaluator = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.FreemarkerEvaluator
    flinkTransformerClassName = com.apple.aml.stargate.flink.transformer.FreemarkerTransformer
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.FreemarkerEvaluator
    optionsClassName = com.apple.aml.stargate.common.options.FreemarkerOptions
    aliases = [Freemarker, FreemarkerEL, FEvaluator]
  }
  FreemarkerFunction = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.FreemarkerFunction
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.FreemarkerFunction
    optionsClassName = com.apple.aml.stargate.common.options.FreemarkerFunctionOptions
    aliases = [FreemarkerLogic, FreemarkerFunc, FreemarkerLambda]
  }
  PredicateFilter = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.PredicateFilter
    optionsClassName = com.apple.aml.stargate.common.options.KVFilterOptions
    aliases = [Predicate, Filter, Conditional, Validate, Verify, Check]
  }
  BatchFunction = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.BatchFunction
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.BatchFunction
    optionsClassName = com.apple.aml.stargate.common.options.BatchFunctionOptions
    aliases = [BatchFunc, BatchLambda, Batch, WindowFunc, WindowLambda, BatchJavaTransformer, BatchJavaTransform, BatchJava]
  }
  Scala = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.JavaFunction
    optionsClassName = com.apple.aml.stargate.common.options.JavaFunctionOptions
    aliases = [ScalaFunction, ScalaFunc, ScalaLambda]
  }
  ExternalFunction = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.ExternalFunction
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.ExternalFunction
    optionsClassName = com.apple.aml.stargate.common.options.ExternalFunctionOptions
    aliases = [External, ExternalFunction, ExternalFunc, ExternalLambda, PythonFunction, PythonFunc, PythonLambda, Python, Jinja, ExternalJvmFunction, ExternalJvmFunc, ExternalJvmLambda, ExternalJvm]
  }
  ExternalBatchFunction = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.ExternalBatchFunction
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.ExternalBatchFunction
    optionsClassName = com.apple.aml.stargate.common.options.ExternalBatchFunctionOptions
    aliases = [ExternalBatch, PythonBatchFunction, PythonBatchFunc, PythonBatchLambda, PythonBatch, ExternalJvmBatchFunction, ExternalJvmBatchFunc, ExternalJvmBatchLambda, ExternalJvmBatch]
  }
  NoOp = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.NoOp
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.NoOp
    optionsClassName = com.apple.aml.stargate.beam.sdk.ts.NoOp
    aliases = [PassThrough, ByPass, Nothing, None, AsIs, DoNothing, Drop, Drain]
  }
  ErrorNode = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.ErrorMarkerNode
    aliases = [Error, Errors, ErrorNode, StargateErrors, StargateErrorNode, AllErrors, Exceptions, AllExceptions]
  }
  SubsetRecord = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.SubsetRecord
    optionsClassName = com.apple.aml.stargate.common.options.SubsetRecordOptions
    aliases = [SubRecord, SubsetRecordExtractor, SubRecordExtractor]
  }
  EnhanceRecord = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.EnhanceRecord
    optionsClassName = com.apple.aml.stargate.common.options.EnhanceRecordOptions
    aliases = [AddRecord, RecordEnhancer, ExpandRecord, EnrichRecord]
  }
  FieldExtractor = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.FieldExtractor
    optionsClassName = com.apple.aml.stargate.common.options.FieldExtractorOptions
    aliases = [ExtractFields]
  }
  IcebergSparkQueryExecutor = {
    transformerClassName = com.apple.aml.stargate.connector.iceberg.IcebergSparkQueryExecutor
    optionsClassName = com.apple.aml.stargate.common.options.SparkFacadeQueryOptions
    aliases = [IcebergSelect, IcebergQuery, IcebergExecutor, ADTQuery, ADTSelect, IcebergQueryExecutor, IcebergSQL, ADTSQL, IcebergSparkQuery, IcebergSpark]
  }
  Iceberg = {
    readerClassName = com.apple.aml.stargate.connector.iceberg.IcebergIO
    writerClassName = com.apple.aml.stargate.connector.iceberg.IcebergIO
    transformerClassName = com.apple.aml.stargate.connector.iceberg.IcebergIO
    optionsClassName = com.apple.aml.stargate.common.options.IcebergOptions
    aliases = [IcebergIngest, IcebergFileIngest, IcebergFileSave, ADTIngest, ADTFileIngest, ADTFileSave, ADT, IcebergS3, IcebergHdfs]
  }
  IcebergOperations = {
    transformerClassName = com.apple.aml.stargate.connector.iceberg.IcebergOperations
    optionsClassName = com.apple.aml.stargate.common.options.IcebergOpsOptions
    aliases = [IcebergOperations, IcebergOperation, IcebergOps, ADTOperations, ADTOperation, ADTOps, IcebergFunctions, IcebergFunction, IcebergFunc, ADTFunctions, ADTFunc]
  }
  ACIKafka = {
    readerClassName = com.apple.aml.stargate.connector.aci.kafka.ACIKafkaIO
    writerClassName = com.apple.aml.stargate.connector.aci.kafka.ACIKafkaIO
    transformerClassName = com.apple.aml.stargate.connector.aci.kafka.ACIKafkaIO
    optionsClassName = com.apple.aml.stargate.common.options.ACIKafkaOptions
    aliases = [PIEKafka, Kaffe, Kafka, MSK]
  }
  S3 = {
    readerClassName = com.apple.aml.stargate.beam.sdk.io.s3.S3IO
    writerClassName = com.apple.aml.stargate.beam.sdk.io.s3.S3IO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.s3.S3IO
    optionsClassName = com.apple.aml.stargate.common.options.S3Options
    aliases = [AWSS3, MINIO]
    writerDefaults = {
      "core.fs.hdfs.impl" = "org.apache.hadoop.hdfs.DistributedFileSystem"
      "core.fs.s3n.impl" = "org.apache.hadoop.fs.s3native.NativeS3FileSystem"
      "core.fs.s3.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
      "core.fs.s3a.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
      "core.fs.s3a.s3.client.factory.impl" = "com.apple.aml.stargate.beam.sdk.fs.s3a.BucketSpecificS3ClientFactory"
      "core.hadoop.security.authentication" = "SIMPLE"
    }
  }
  Hdfs = {
    readerClassName = com.apple.aml.stargate.beam.sdk.io.hadoop.HdfsIO
    writerClassName = com.apple.aml.stargate.beam.sdk.io.hadoop.HdfsIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.hadoop.HdfsIO
    optionsClassName = com.apple.aml.stargate.common.options.HdfsOptions
    aliases = [Hadoop, Hive, HdfsStreaming]
    writerDefaults = {
      "core.hadoop.security.token.service.use_ip" = "false"
      "core.hadoop.security.authentication" = "kerberos"
      "core.hadoop.security.authorization" = "true"
      "core.hadoop.rpc.protection" = "authentication"
      "core.fs.hdfs.impl" = "org.apache.hadoop.hdfs.DistributedFileSystem"
      "core.fs.s3n.impl" = "org.apache.hadoop.fs.s3native.NativeS3FileSystem"
      "core.fs.s3.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
      "core.fs.s3a.impl" = "org.apache.hadoop.fs.s3a.S3AFileSystem"
      "core.fs.s3a.s3.client.factory.impl" = "com.apple.aml.stargate.beam.sdk.fs.s3a.BucketSpecificS3ClientFactory"
      "hdfs.dfs.datanode.kerberos.principal.pattern" = "*"
      "hdfs.dfs.namenode.kerberos.principal.pattern" = "*"
      "hdfs.dfs.ha.automatic-failover.enabled" = "true"
      "hdfs.dfs.namenode.acls.enabled" = "true"
      "hdfs.dfs.data.transfer.protection" = "privacy"
      "hdfs.dfs.permissions.enabled" = "true"
      "hdfs.dfs.block.access.token.enable" = "true"
      "hive.hive.metastore.sasl.enabled" = "true"
    }
  }
  FileSystem = {
    readerClassName = com.apple.aml.stargate.beam.sdk.io.file.GenericFileIO
    writerClassName = com.apple.aml.stargate.beam.sdk.io.file.GenericFileIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.file.GenericFileIO
    optionsClassName = com.apple.aml.stargate.common.options.FileOptions
    aliases = [Local, DiskIO, LocalFS, Disk, File, FileIO, NoOpFile, NoOpWindow]
  }
  HdfsOperations = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.hadoop.HdfsOperations
    optionsClassName = com.apple.aml.stargate.common.options.HdfsOpsOptions
    aliases = [HadoopOperations, HadoopOperation, HdfsOperations, HdfsOperation, HdfsOps, HdfsFunctions, HdfsFunction, HdfsFunc, HadoopFunctions, HadoopFunc]
  }
  Attributes = {
    readerClassName = com.apple.aml.stargate.connector.athena.attributes.AttributesIO
    writerClassName = com.apple.aml.stargate.connector.athena.attributes.AttributesIO
    transformerClassName = com.apple.aml.stargate.connector.athena.attributes.AttributesIO
    optionsClassName = com.apple.aml.stargate.common.options.AttributesOptions
    aliases = [AthenaAttributes, AMLAttributes, Lookups, AthenaLookups, AMLLookups]
  }
  AttributesOperations = {
    writerClassName = com.apple.aml.stargate.connector.athena.attributes.AttributesOperations
    transformerClassName = com.apple.aml.stargate.connector.athena.attributes.AttributesOperations
    optionsClassName = com.apple.aml.stargate.common.options.AttributesOpsOptions
    aliases = [AttributesOps, AttributeOps, AttributeReadOps, AttributeWriteOps]
  }
  Jdbc = {
    readerClassName = com.apple.aml.stargate.beam.sdk.io.jdbc.GenericJdbcIO
    writerClassName = com.apple.aml.stargate.beam.sdk.io.jdbc.GenericJdbcIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.jdbc.GenericJdbcIO
    optionsClassName = com.apple.aml.stargate.common.options.JdbiOptions
    aliases = [AnsiSQL, Rdbms, Postgres, PostgreSQL, RDS, Oracle, Teradata]
  }
  JdbcOperations = {
    writerClassName = com.apple.aml.stargate.beam.sdk.io.jdbc.JdbcOperations
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.jdbc.JdbcOperations
    optionsClassName = com.apple.aml.stargate.common.options.JdbiOptions
    aliases = [JdbcOps, RDSOps, PostgresOps, PostgreSQLOps, SqlOps]
  }
  Snowflake = {
    writerClassName = com.apple.aml.stargate.beam.sdk.io.snowflake.SnowflakeIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.snowflake.SnowflakeIO
    optionsClassName = com.apple.aml.stargate.common.options.SnowflakeOptions
    aliases = [Snow]
  }
  SnowflakeOperations = {
    writerClassName = com.apple.aml.stargate.beam.sdk.io.snowflake.SnowflakeOperations
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.snowflake.SnowflakeOperations
    optionsClassName = com.apple.aml.stargate.common.options.SnowflakeOptions
    aliases = [SnowOps, SnowflakeOps]
  }
  Solr = {
    readerClassName = com.apple.aml.stargate.beam.sdk.io.solr.GenericSolrIO
    writerClassName = com.apple.aml.stargate.beam.sdk.io.solr.GenericSolrIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.solr.GenericSolrIO
    optionsClassName = com.apple.aml.stargate.common.options.SolrOptions
    aliases = [AthenaSolr]
  }
  SaveState = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.SaveState
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.SaveState
    optionsClassName = com.apple.aml.stargate.common.options.StateOptions
    aliases = [StateSave, SaveState, Checkpoint, SaveStateAndCallBack]
  }
  GetState = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.GetState
    optionsClassName = com.apple.aml.stargate.common.options.StateOptions
    aliases = [GetState, FetchState, FetchFullState, FetchCurrentState, CurrentState, GetCurrentState]
  }
  Dhari = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.Dhari
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.Dhari
    optionsClassName = com.apple.aml.stargate.common.options.DhariOptions
    aliases = [PublishToKafka, KafkaPublish, DhariPayload, PublishPayload]
  }
  DhariSDKClient = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.DhariSDKClient
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.DhariSDKClient
    optionsClassName = com.apple.aml.stargate.common.options.DhariOptions
    aliases = [DhariClient, DhariSDK, AMLSDK, DataPlatformSDK, AMLDP, DP, DhariKafka]
  }
  Log = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.Log
    flinkWriterClassName = com.apple.aml.stargate.flink.sink.LogSink
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.Log
    optionsClassName = com.apple.aml.stargate.beam.sdk.ts.Log
    aliases = [Logger, Print, SysOut]
  }
  Splunk = {
    readerClassName = com.apple.aml.stargate.beam.sdk.io.splunk.GenericSplunkIO
    writerClassName = com.apple.aml.stargate.beam.sdk.io.splunk.GenericSplunkIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.splunk.GenericSplunkIO
    optionsClassName = com.apple.aml.stargate.common.options.SplunkOptions
    aliases = [HEC, SplunkForwarder, FluentD, RawLog, RawSplunk]
  }
  Http = {
    writerClassName = com.apple.aml.stargate.beam.sdk.io.http.HttpIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.http.HttpIO
    optionsClassName = com.apple.aml.stargate.common.options.HttpInvokerOptions
    aliases = [Rest, WebService, Post, HttpGet, HttpPost]
  }
  LocalOfs = {
    writerClassName = com.apple.aml.stargate.beam.sdk.io.http.LocalOfsIO
    transformerClassName = com.apple.aml.stargate.beam.sdk.io.http.LocalOfsIO
    optionsClassName = com.apple.aml.stargate.common.options.LocalOfsOptions
    aliases = [LocalKVOfs, LocalRelationalOfs, LocalKV, InMemoryOfs, OfsCache]
  }
  ACICassandra = {
    readerClassName = com.apple.aml.stargate.connector.aci.cassandra.ACICassandraIO
    writerClassName = com.apple.aml.stargate.connector.aci.cassandra.ACICassandraIO
    optionsClassName = com.apple.aml.stargate.common.options.ACICassandraOptions
    aliases = [PIECassandra]
  }
  Stratos = {
    readerClassName = com.apple.aml.stargate.connector.stratos.StratosQueueIO
    optionsClassName = com.apple.aml.stargate.common.options.StratosOptions
    aliases = [GenevaQueue, StratosQueue]
  }
  BeamSQL = {
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.BeamSQL
    optionsClassName = com.apple.aml.stargate.common.options.BeamSQLOptions
    aliases = [SQL]
  }
  FlinkSQL = {
      flinkReaderClassName = com.apple.aml.stargate.flink.source.SqlSource
      flinkTransformerClassName = com.apple.aml.stargate.flink.transformer.SqlTransformer
      flinkWriterClassName = com.apple.aml.stargate.flink.sink.SqlSink
      optionsClassName = com.apple.aml.stargate.common.options.FlinkSqlOptions
      aliases = [FlinkSQL,FlinkSQLSource,FlinkSQLTransformer,FlinkSQLSink]
  }
  MetricNode = {
    writerClassName = com.apple.aml.stargate.beam.sdk.ts.MetricNode
    transformerClassName = com.apple.aml.stargate.beam.sdk.ts.MetricNode
    optionsClassName = com.apple.aml.stargate.common.options.MetricNodeOptions
    aliases = [Metric, Prometheus, Metrics]
  }
}
stargate.runner.config {
  flink = {
    className = org.apache.beam.runners.flink.FlinkRunner
    version = 1.16
    coordinator = {
      ports = {
        "jobmanager.rpc.port" = 6123
        "blob.server.port" = 6124
        "queryable-state.proxy.ports" = 6125
        "webui.port" = 8081
        "rm.port" = 8888
        "scheduler.queue.port" = 8788
      }
      livenessPort = 6123
      command = "/opt/flink/docker-entrypoint.sh"
      arguments = ["standalone-job", "--job-classname com.apple.aml.stargate.pipeline.boot.Executor"]
      labels = {
        "component" = "jobmanager"
      }
    }
    worker = {
      ports = {
        "taskmanager.rpc.port" = 6122
        "rm.port" = 8888
      }
      livenessPort = 6122
      command = "/opt/flink/docker-entrypoint.sh"
      arguments = ["taskmanager"]
      labels = {
        "component" = "taskmanager"
      }
    }
    configData = {
      "/opt/flink/conf/flink-conf.yaml" = {
        "taskmanager.runtime.large-record-handler" = "true"
        "taskmanager.network.memory.buffer-debloat.enabled" = "true"
        "cluster.evenly-spread-out-slots" = "true"
        "execution.checkpointing.unaligned.enabled" = "true"
        "execution.checkpointing.unaligned" = "true"
        "security.module.factory.classes" = "org.apache.flink.runtime.security.modules.HadoopModuleFactory;org.apache.flink.runtime.security.modules.ZookeeperModuleFactory"
        "rest.flamegraph.enabled" = "true"
        "metrics.reporters" = "stargate"
        "metrics.reporter.stargate.factory.class" = "com.apple.aml.stargate.runners.flink.utils.FlinkMetricReporterFactory"
        "state.backend" = "hashmap"
        "state.backend.incremental" = "true"
        "execution.checkpointing.interval" = "10s"
        "execution.checkpointing.min-pause" = "5s"
        "execution.checkpointing.timeout" = "3600s"
        "execution.checkpointing.aligned-checkpoint-timeout" = "3000s"
        "restart-strategy" = "exponential-delay"
        "restart-strategy.fixed-delay.attempts" = "10"
        "restart-strategy.fixed-delay.delay" = "30 s"
        "restart-strategy.exponential-delay.initial-backoff" = "10 s"
        "restart-strategy.exponential-delay.max-backoff" = "20 min"
        "restart-strategy.exponential-delay.backoff-multiplier" = "2.0"
        "restart-strategy.exponential-delay.reset-backoff-threshold" = "90 min"
        "restart-strategy.exponential-delay.jitter-factor" = "0.1"
      }
    }
    env = {}
  }
  nativeflink = {
      className = org.apache.beam.runners.flink.FlinkRunner
      version = 1.16
      coordinator = {
        ports = {
          "jobmanager.rpc.port" = 6123
          "blob.server.port" = 6124
          "queryable-state.proxy.ports" = 6125
          "webui.port" = 8081
          "rm.port" = 8888
          "scheduler.queue.port" = 8788
        }
        livenessPort = 6123
        command = "/opt/flink/docker-entrypoint.sh"
        arguments = ["standalone-job", "--job-classname com.apple.aml.stargate.pipeline.boot.Executor"]
        labels = {
          "component" = "jobmanager"
        }
      }
      worker = {
        ports = {
          "taskmanager.rpc.port" = 6122
          "rm.port" = 8888
        }
        livenessPort = 6122
        command = "/opt/flink/docker-entrypoint.sh"
        arguments = ["taskmanager"]
        labels = {
          "component" = "taskmanager"
        }
      }
      configData = {
        "/opt/flink/conf/flink-conf.yaml" = {
          "taskmanager.runtime.large-record-handler" = "true"
          "taskmanager.network.memory.buffer-debloat.enabled" = "true"
          "cluster.evenly-spread-out-slots" = "true"
          "execution.checkpointing.unaligned.enabled" = "true"
          "execution.checkpointing.unaligned" = "true"
          "security.module.factory.classes" = "org.apache.flink.runtime.security.modules.HadoopModuleFactory;org.apache.flink.runtime.security.modules.ZookeeperModuleFactory"
          "rest.flamegraph.enabled" = "true"
          "metrics.reporters" = "stargate"
          "metrics.reporter.stargate.factory.class" = "com.apple.aml.stargate.runners.flink.utils.FlinkMetricReporterFactory"
          "state.backend" = "hashmap"
          "state.backend.incremental" = "true"
          "execution.checkpointing.interval" = "10s"
          "execution.checkpointing.min-pause" = "5s"
          "execution.checkpointing.timeout" = "3600s"
          "execution.checkpointing.aligned-checkpoint-timeout" = "3000s"
          "restart-strategy" = "exponential-delay"
          "restart-strategy.fixed-delay.attempts" = "10"
          "restart-strategy.fixed-delay.delay" = "30 s"
          "restart-strategy.exponential-delay.initial-backoff" = "10 s"
          "restart-strategy.exponential-delay.max-backoff" = "20 min"
          "restart-strategy.exponential-delay.backoff-multiplier" = "2.0"
          "restart-strategy.exponential-delay.reset-backoff-threshold" = "90 min"
          "restart-strategy.exponential-delay.jitter-factor" = "0.1"
        }
      }
      env = {}
  }
  spark = {
    className = org.apache.beam.runners.spark.SparkRunner
    version = 3.2.3
    coordinator = {
      ports = {
        "rm.port" = 8888
        "scheduler.queue.port" = 8788
      }
      livenessPort = 8888
      labels = {
        "component" = "driver"
      }
    }
    worker = {
      ports = {
        "rm.port" = 8888
      }
      livenessPort = 8888
      labels = {
        "component" = "executor"
      }
    }
    configData = {}
    env = {}
  }
  driver = {
    className = org.apache.beam.runners.direct.DirectRunner
    version = 3.2.3
    coordinator = {
      ports = {
        "rm.port" = 8888
        "scheduler.queue.port" = 8788
      }
      livenessPort = 8888
      command = "stargate-executor"
      labels = {
        "component" = "driver"
      }
    }
    worker = {
      ports = {
        "rm.port" = 8888
      }
      livenessPort = 8888
      labels = {
        "component" = "executor"
      }
    }
    configData = {}
    env = {}
  }
  direct = {
    className = org.apache.beam.runners.direct.DirectRunner
    version = 0.0
    coordinator = {
      ports = {
        "rm.port" = 8888
        "scheduler.queue.port" = 8788
      }
      livenessPort = 8888
      command = "stargate-executor"
      labels = {
        "component" = "stargate-executor"
      }
    }
    worker = {
      ports = {
        "rm.port" = 8888
      }
      livenessPort = 8888
      command = "stargate-executor"
      labels = {
        "component" = "stargate-executor"
      }
    }
    configData = {}
    env = {}
  }
}
stargate.deployment.entrypoint = {
  className = com.apple.aml.stargate.pipeline.boot.Executor
  jarUri = "local:///opt/stargate/lib/aml-stargate-executor.jar"
  whisper.default.filePath = /whisper/app/connectId.properties
}
stargate.deployment.docker.image = {
  splunkForwarder = "docker.apple.com/splunk-ist/splunk-%sforwarder"
  splunkForwarder = ${?STARGATE_DEPLOYMENT_DOCKER_SPLUNK_FORWARDER}
  executor = "docker.apple.com/aml/stargate-executor"
  executor = ${?STARGATE_DEPLOYMENT_DOCKER_EXECUTOR}
  busybox = "docker.apple.com/busybox"
  busybox = ${?STARGATE_DEPLOYMENT_DOCKER_BUSYBOX}
  javaBase = "docker.apple.com/base-images/ubi9/java11-builder"
  javaBase = ${?STARGATE_DEPLOYMENT_DOCKER_JAVA}
  executorPrefix = "docker.apple.com/aml/stargate-executor:"
  executorPrefix = ${?STARGATE_DEPLOYMENT_DOCKER_EXECUTOR_PREFIX}
}
stargate.sensitive.jsonKeys = ["apiToken", "privateKey", "publicKey", "password", "accessKey", "secretKey", "pipelineToken", "pipeline.token", "public-key", "encrypted-secret-key", "verification.key"]
stargate.sensitive.redactRegexs = {
  "((secret|password|user|username|access|(private\\.key)|(verification\\.key)|token)([^:=]*)([:=]+))([^\\r\\n=:, \\t]+)" = "$1********"
}
stargate.schemaMappings.sqlToAvro = {
  "char" = "string",
  "clnt" = "string",
  "cuky" = "string",
  "dats" = "double",
  "dec" = "string",
  "lang" = "string",
  "numc" = "string",
  "unit" = "string",
  "bool" = "boolean",
  "integer" = "int",
  "decimal" = "double",
  "number" = "double",
  "varchar" = "string",
  "char" = "string",
  "text" = "string",
  "blob" = "binary",
  "bigint" = "long",
  "biginteger" = "long"
}
stargate.s3.defaults.blockSize = 33554432
stargate.s3.defaults.blockSize = ${?APP_S3_DEFAULT_BLOCKSIZE}
stargate.s3.defaults.blockSize = ${?STARGATE_S3_DEFAULT_BLOCKSIZE}
stargate.sink.channel.inmemory.directcopy.enabled = false
stargate.sink.channel.inmemory.directcopy.enabled = ${?STARGATE_SINK_INMEMORY_DIRECTCOPY_ENABLED}
hubble.enabled = true
hubble.apps.path = {
  AppName = stargate
  DatacenterName = local
  PODName = local
  HostName = localhost
  InstanceName = stargate-local
  AppName = ${?PLATFORM_APPLICATION_ID}
  DatacenterName = ${?PLATFORM_PROCESS_NAME}
  PODName = ${?PLATFORM_WORK_UNIT_ID}
  HostName = ${?PLATFORM_JOB_ID}
  HostName = ${?HOSTNAME}
  InstanceName = ${?PLATFORM_SHORT_INSTANCE_ID}
}
hubble.channel.http.auth.token = ${?APP_METRICS_HUBBLE_PUBLISH_KEY}
hubble.channel.http.auth.token = ${?STARGATE_HUBBLE_PUBLISH_TOKEN}
hubble.custom.prefix = "stargate."
LOCAL.hubble.custom.prefix = "stargate.local."
DEV.hubble.custom.prefix = "stargate.dev."
QA.hubble.custom.prefix = "stargate.qa."
UAT.hubble.custom.prefix = "stargate.uat."
hubble.custom.prefix = ${?STARGATE_HUBBLE_METRIC_PREFIX}
LOCAL.hubble.custom.prefix = ${?STARGATE_HUBBLE_METRIC_PREFIX}
DEV.hubble.custom.prefix = ${?STARGATE_HUBBLE_METRIC_PREFIX}
QA.hubble.custom.prefix = ${?STARGATE_HUBBLE_METRIC_PREFIX}
UAT.hubble.custom.prefix = ${?STARGATE_HUBBLE_METRIC_PREFIX}
hubble.publisher.frequency = 10
hubble.publisher.frequency = ${?APP_METRICS_PUBLISH_FREQUENCY}
prometheus.metrics.buildinfo.enabled = false
prometheus.metrics.buildinfo.enabled = ${?APP_METRICS_BUILDINFO_ENABLED}
prometheus.metrics.buildinfo.enabled = ${?APP_METRICS_ALL_ENABLED}
prometheus.metrics.jmx.enabled = false
prometheus.metrics.jmx.enabled = ${?APP_METRICS_JMX_ENABLED}
prometheus.metrics.jmx.enabled = ${?APP_METRICS_ALL_ENABLED}
prometheus.metrics.jvmdefaults.enabled = false
prometheus.metrics.jvmdefaults.enabled = ${?APP_METRICS_JVM_DEFAULTS_ENABLED}
prometheus.metrics.jvmdefaults.enabled = ${?APP_METRICS_ALL_ENABLED}
prometheus.metrics.opencensus.enabled = false
prometheus.metrics.opencensus.enabled = ${?APP_METRICS_OPENCENSUS_ENABLED}
prometheus.metrics.opencensus.enabled = ${?APP_METRICS_ALL_ENABLED}
prometheus.metrics.flink.enabled = false
prometheus.metrics.flink.enabled = ${?APP_METRICS_OPENCENSUS_ENABLED}
prometheus.metrics.flink.enabled = ${?APP_METRICS_ALL_ENABLED}
prometheus.metrics.kafkaclient.enabled = false
prometheus.metrics.kafkaclient.enabled = ${?APP_METRICS_KAFKA_CLIENT_ENABLED}
prometheus.metrics.kafkaclient.enabled = ${?APP_METRICS_ALL_ENABLED}
prometheus.kafka.metrics.sync.frequency = 1
prometheus.kafka.metrics.sync.frequency = ${?APP_METRICS_KAFKA_PROMETHEUS_SYNC_FREQUENCY}
prometheus.buckets.default.type = exponential
prometheus.buckets.default.type = ${?APP_METRICS_PROMETHEUS_DEFAULT_BUCKET_TYPE}
prometheus.buckets.default.start = 0.25
prometheus.buckets.default.start = ${?APP_METRICS_PROMETHEUS_DEFAULT_BUCKET_START}
prometheus.buckets.default.factor = 1.5
prometheus.buckets.default.factor = ${?APP_METRICS_PROMETHEUS_DEFAULT_BUCKET_FACTOR}
prometheus.buckets.default.width = 0.5
prometheus.buckets.default.width = ${?APP_METRICS_PROMETHEUS_DEFAULT_BUCKET_WIDTH}
prometheus.buckets.default.count = 21
prometheus.buckets.default.count = ${?APP_METRICS_PROMETHEUS_DEFAULT_BUCKET_COUNT}
stargate.prometheus.server.port = 8888
stargate.prometheus.server.port = ${?STARGATE_PROMETHEUS_PORT}
stargate.schemastore.client.secretKey = ${?APP_SCHEMA_STORE_API_TOKEN}
schemas.avro.additional.registration.schemaReference = UAT8
schemas.avro.additional.registration.schemaReference = ${?APP_SCHEMA_STORE_ADDITIONAL_REGISTRATION_REFERENCE}
PROD.schemas.avro.additional.registration.schemaReference = PROD
stargate.cache.schema.expiry = 10
stargate.cache.schema.expiry = ${?APP_CACHE_SCHEMA_EXPIRY}
stargate.cache.kerberos.login.expiry = 30
stargate.cache.kerberos.login.expiry = ${?APP_CACHE_KERBEROS_LOGIN_EXPIRY}
PROD.stargate.cache.schema.expiry = 60
PROD.stargate.cache.schema.expiry = ${?APP_CACHE_SCHEMA_EXPIRY}
spring.main.banner-mode = off
ccclient.localmode.enabled = false
ccclient.localmode.enabled = ${?APP_CCCLIENT_LOCAL_MODE_ENABLED}
stargate.versionInfo.version = 0.0.0
stargate.versionInfo.tag = local
stargate.versionInfo.buildTime = local
appconfig.default.module.id = M01128
